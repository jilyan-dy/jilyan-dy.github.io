[
	{
		"id": "1",
		"topic": "nlp",
		"title": "At Home with Alexa: A Tale of Two Conversational Agents. In: Text, Speech, and Dialogue",
		"authors": "Ureta, J., Brito, C. I., Dy, J. B., Santos, K. A., Villaluna, W., & Ong, E.",
		"publisher": "International Conference on Text, Speech, and Dialogue",
		"publicationDate": "2020.09",
		"link": "https://drive.google.com/file/d/19rpwV82xmeV1z2m5BF8xkDQfChblDX2s/view?usp=sharing",
		"abstract": "Voice assistants in mobile devices and smart speakers offer the potential of conversational agents as storytelling peers of children, especially those who may have limited proficiency in spelling and grammar. Despite their prevalence, however, the built-in automatic speech recognition features of voice interfaces have been shown to perform poorly on children’s speech, which may affect child-agent interaction. In this paper, we describe our experiments in deploying a conversational storytelling agent on two popular commercial voice interfaces - Google Assistant and Amazon Alexa. Through post-validation feedback from children and analysis of the captured conversation logs, we compare the challenges encountered by children when sharing their stories with these voice assistants. We also used the Bilingual Evaluation Understudy to provide a quantitative assessment of the text-to-speech transcription quality. We found that voice assistants’ short waiting time and the frequent yet misplaced interruptions during pauses disrupt the thinking process of children. Furthermore, disfluencies and grammatical errors that naturally occur in children’s speech affected the transcription quality."
	},

	{
		"id": "2",
		"topic": "nlp",
		"title": "Acquiring Commonsense Knowledge during Collaborative Storytelling",
		"authors": "Dy, J., Brito, C., Tan, V., Lola, J., & Ong, E.",
		"publisher": "IOP Conference Series: Materials Science and Engineering (Vol. 1077, No. 1, p. 012023)",
		"publicationDate": "2021.02",
		"link": "https://drive.google.com/file/d/1SkNbt8wToyO5JUYXVqAMvFM4ePDLmeJK/view?usp=sharing",
		"abstract": "Conversational agents that engage children in collaborative storytelling need a collection of domain knowledge to formulate its responses. However, the current manual processes of collecting, annotating and extracting data from a corpus of unstructured text is time-consuming that often impedes the population of a knowledge base. An alternative is to design the agent as a teachable peer that can continuously learn from its human users. In this paper, we describe a storytelling agent that can expand its domain knowledge base by learning new assertions from its story-based conversation with children. We also use conversations as a means of validating the acquired knowledge. Results showed that the agent can achieve a recall value from 83% to 94% in extracting capabilities, property and instance relations while encountering difficulty in identifying assertions that describe the location of story events. Analysis of the conversation logs showed that the performance of the agent is affected by how children describe the characters and events in their stories."
	},

	{
		"id": "3",
		"topic": "cv",
		"title": "Lightweight Face Anti-Spoofing Network for Telehealth Applications",
		"authors": "Lin, J. D., Lin, H. H., Dy, J., Chen, J. C., Tanveer, M., Razzak, I., & Hua, K. L.",
		"publisher": "IEEE Journal of Biomedical and Health Informatics",
		"publicationDate": "2021.08",
		"link": "https://drive.google.com/file/d/1H-w04B3lTmhEWmbEFlqoWJNfWktjjIJA/view?usp=sharing",
		"abstract": "Online healthcare applications have grown more popular over the years. For instance,telehealth is an online healthcare application that allows patients and doctors to schedule consultations,prescribe medication,share medical documents,and monitor health conditions conveniently. Apart from this,telehealth can also be used to store a patients personal and medical information. Given the amount of sensitive data it stores,security measures are necessary. With its rise in usage due to COVID-19,its usefulness may be undermined if security issues are not addressed. A simple way of making these applications more secure is through user authentication. One of the most common and often used authentications is face recognition. It is convenient and easy to use. However,face recognition systems are not foolproof. They are prone to malicious attacks like printed photos,paper cutouts,re-played videos,and 3D masks. In order to counter this,multiple face anti-spoofing methods have been proposed. The goal of face anti-spoofing is to differentiate real users (live) from attackers (spoof). Although effective in terms of performance,existing methods use a significant amount of parameters,making them resource-heavy and unsuitable for handheld devices. Apart from this,they fail to generalize well to new environments like changes in lighting or background. This paper proposes a lightweight face anti-spoofing framework that does not compromise on performance. A lightweight model is critical for applications like telehealth that run on handheld devices. Our proposed method achieves good performance with the help of an ArcFace Classifier (AC). The AC encourages differentiation between spoof and live samples by making clear boundaries between them. With clear boundaries,classification becomes more accurate. We further demonstrate our models capabilities by comparing the number of parameters,FLOPS,and performance with other state-of-the-art methods."
	},

	{
		"id": "4",
		"topic": "cv",
		"title": "VDNet: Video Deinterlacing Network Based on Coarse Adaptive Module and Deformable Recurrent Residual Network",
		"authors": "Yeh, Y. C., Dy, J., Huang, T. M., Chen, Y. Y., & Hua, K. L.",
		"publisher": "Neural Computing and Applications",
		"publicationDate": "2022.03",
		"link": "https://drive.google.com/file/d/10cnibE1GtSYs0vKCpycXgliWTRA10a2z/view?usp=sharing",
		"abstract": "Interlacing is the technique that overlaps odd lines from an odd frame and even lines from an even frame to increase the perceived frame rate in TV displays without increasing bandwidth. On the other hand, since original frames are not stored, deinterlacing is the technique introduced for reversing this process and restore the original or progressive video. Existing deinterlacing approaches focus on restoring a single interlaced frame without optimally leveraging the temporal information available. In this paper, we propose VDNet, which to the best of our knowledge, is the first deep learning-based deinterlacing framework that considers inter-frame correlation. Our proposed method addresses deinterlacing by splitting the frames and regenerating the missing lines using a simple coarse method (base image sequence) before combining them with the residual image sequence for refinement. For the deinterlaced base image sequence, our data module uses spatial and temporal information to fill in the missing areas and leverages our coarse adaptive module to interpolate them. The residual module then leverages our proposed Deformable Recurrent Residual Network to optimally enhance and aggregate the features extracted from the interlaced video. Our method then refines the base image sequence using the residual image sequence generated from the residual module. After reconstructing the progressive frames, our proposed Spatial-Temporal Correlation Loss uses the information provided by the existing interlaced video to further smooth and boost the deinterlaced output. We perform extensive experiments to demonstrate our proposed VDNet’s incredible quantitative performance. Moreover, we design our model to be lightweight and efficient."
	},

	{
		"id": "5",
		"topic": "cv",
		"title": "SSRFace: A face Recognition Framework Against Shallow Data",
		"authors": "Zhou, Y.T., Dy, J.B., Hsu, S.C., Hsu, Y.L., Yang, C.L., Hua, K.L.",
		"publisher": "Multimedia Tools and Applications",
		"publicationDate": "2022.11",
		"link": "https://drive.google.com/file/d/1q05r6Mc2usUjJVEBFbqFfoDzvZI7uZEp/view?usp=sharing",
		"abstract": "Most existing deep-learning-based approaches rely on high-resolution large-scale datasets to improve their performance. However, obtaining such datasets is challenging for tasks such as face recognition. The best way to address this is first to address the issue deep-learning-based approaches experience when trained on limited samples or shallow datasets (i.e., lack of diversity). We propose SSRFace, a framework for face recognition on shallow datasets. In detail, SSRFace leverages two novel components: Segregate-Representation (SR) and SimInstance. SR utilizes unlabeled data and angular-margin-based loss to increase inter-class distance, improving class discrimination. SimInstance, on the other hand, has a straightforward approach to improving intra-class diversity. Our proposed SimInstance starts by learning the unique class distribution from the few samples before randomly sampling a feature representation to serve as new intra-class samples. We train our model on TinyFace, a shallow dataset, to show its capabilities. We show SSRFace performed better than other existing approaches with Rank-1 accuracy and mean average precision (mAP) when trained on shallow datasets."
	},

	{
		"id": "6",
		"topic": "cv",
		"title": "MCGAN: Mask Controlled Generative Adversarial Network for Image Retargeting",
		"authors": "Dy, J.B., Virtusio, J.J., Tan, D.S., Lin, Y.X., Ilao, J., Chen, Y.Y., Hua, K.L.",
		"publisher": "Neural Computing and Applications",
		"publicationDate": "2023.02",
		"link": "https://drive.google.com/file/d/1npdFyQj_NyznjlpBoFT5AKIETRAaBgwE/view?usp=sharing",
		"abstract": "Image retargeting aims to resize a photograph without distorting its content. Recent solutions leverage generative adversarial networks (GANs) to learn an image’s internal distribution. Patches are then replicated and generated to fill the target aspect ratio to preserve the internal distribution. Although these approaches are somewhat successful, they do not have a sense of image semantics or the image’s contents, causing semantic errors during generation (e.g., a person with two heads). Our model addresses this by allowing user intervention. The users can preserve the objects they desire through user-defined masks. Our model enforces the masked object to appear at the user-defined location. It also utilizes a de-association regularizer to loosen the association of the selected object with its surroundings. Our method prevents object distortion and enables the user to remove or relocate the object from the input image while allowing the user to set its target size."
	}
]

